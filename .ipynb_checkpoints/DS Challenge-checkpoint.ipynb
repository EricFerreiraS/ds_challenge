{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1\n",
    "\n",
    "Classes:\n",
    "    - Promotor\n",
    "    - Detrator\n",
    "    - Neutro\n",
    "Só 100 notícias são classificadas\n",
    "Os conteúdos são rankeados por alcance\n",
    "    - No grupo com os 50 maiores alcances, todos são classificados manualmente\n",
    "    - O restante, 50 são selecionados aleatoriamentes e classificados manualmente\n",
    "    - Alcance por grupo\n",
    "    \n",
    "Calcular margem de erro do índice\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_top = 1000000 * (15/50)\n",
    "alcance_detrator_top = 1000000 * (8/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_res = 3000000 * (17/50)\n",
    "alcance_detrator_res = 3000000 * (7/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_total = alcance_promotor_top + alcance_promotor_res\n",
    "alcance_detrator_total = alcance_detrator_top + alcance_detrator_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_promotor_top = alcance_promotor_total / (alcance_promotor_top + alcance_detrator_top)\n",
    "indice_promotor_res = alcance_promotor_total / (alcance_promotor_res+alcance_detrator_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.869565217391304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_promotor_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666665"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_promotor_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margem_erro(populacao, amostra, p=0.5, z = 1.96):\n",
    "    '''\n",
    "    p: percentual (como não tem definido, escolhe 50% que é a pior)\n",
    "    z: valor referente a tabela de distribuição da normal (referente a 95% de confiança)\n",
    "    '''\n",
    "    return cmath.sqrt(-(z**2*p*(1-p)*(amostra-populacao))/(amostra*populacao)).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro TOP 50\n",
    "margem_erro(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13214317304279544"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro Restante\n",
    "margem_erro(550,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08946135105917713"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro de amostra 100 da população de 600\n",
    "margem_erro(600,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resposta Questão 1\n",
    "\n",
    "A geração do índice depende do alcance de cada grupo. Para verificar a margem de erro do índice, a margem de erro dos grupos deve ser levado em consideração.\n",
    "\n",
    "Utilizando a fórmula para descobrir o tamanho da amostra (https://pt.wikihow.com/Calcular-o-Tamanho-de-uma-Amostra) os dados de cada amostra foram utilizadas. (obs: 95% de confiança foi utilizado)\n",
    "\n",
    "Para o grupo Top 50, como é um grupo controlado onde a população e amostra podem ser consideradas iguais, a margem de erro é 0. Já o restante, a marge de erro é cerca de 13% pois utilizo uma amostra de 50 de uma população de 550. Novamente, como o índice utiliza de ambos o grupo para compor o valor, essa margem será passada para o índice.\n",
    "\n",
    "Se ao invés de segmentar utilizasse uma amostra de 100, a margem de erro seria menor (cerca de 8.95%) o que seria melhor para o índice.\n",
    "\n",
    "Link de calculadoras:\n",
    "- https://www.solvis.com.br/calculos-de-amostragem/\n",
    "- https://pt.surveymonkey.com/mp/margin-of-error-calculator/\n",
    "- https://www.opinionbox.com/calculadora-margem-de-erro/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4\n",
    "\n",
    "Agrupar notícias por assunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo\n",
    "df = pd.read_csv(filepath_or_buffer='agrupamento_eventos_new.csv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-01-22', '2020-01-29', '2020-01-08', '2020-01-06',\n",
       "       '2020-01-28', '2020-01-02', '2020-01-23', '2020-01-07',\n",
       "       '2020-01-20', '2020-01-15', '2020-01-01', '2020-01-14',\n",
       "       '2020-01-17', '2020-01-27', '2020-01-13', '2020-01-16',\n",
       "       '2020-01-09', '2020-01-21', '2020-01-10', '2020-01-03',\n",
       "       '2020-01-18', '2020-01-26', '2020-01-19', '2020-01-12',\n",
       "       '2020-01-05', '2020-01-24', '2020-01-11', '2020-01-04',\n",
       "       '2020-01-25'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando as datas únicas\n",
    "df.Data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordenando pela data\n",
    "df = df.sort_values(by=['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando data em datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import de bibliotecas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import corpus\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#stopwords em portugues + duas palavras que não estavam incluídas\n",
    "stopwords_pt = corpus.stopwords.words('portuguese')\n",
    "stopwords_pt.append('ainda')\n",
    "stopwords_pt.append('ser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geração do vocabulário, onde seleciono apenas palavras que aparecem em menos de 80% no documento e\n",
    "#em pelo menos 2 documentos diferentes. Também são retirados as stopwords e consideram apenas palavras com mais \n",
    "#de 3 letras. Todas as palavras são colocadas em caixa baixa\n",
    "def vocab_generation(df):\n",
    "    count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=stopwords_pt, lowercase=True, token_pattern=r'(?u)\\b[a-zA-Z_.]{3,}\\b')\n",
    "    doc_term_matrix = count_vect.fit_transform(df)\n",
    "    return doc_term_matrix, count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#busca pelos melhores parâmetros para o algoritmo. Quantidade de topicos e taxa de aprendizado\n",
    "def best_param(df,n_topic=[3,4,5,6,7,8,9],learning_decay=[.5, .7, .9]):\n",
    "    search_params = {'n_components': n_topic, 'learning_decay': learning_decay}\n",
    "    lda = LatentDirichletAllocation()\n",
    "    model = GridSearchCV(lda, param_grid=search_params,n_jobs=2,cv=5)\n",
    "    model.fit(df)\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo LDA\n",
    "def lda_model(df,n_components_, learning_decay_):\n",
    "    LDA = LatentDirichletAllocation(n_components=n_components_,learning_decay =learning_decay_, random_state=7)\n",
    "    LDA.fit(df)\n",
    "    return LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que recebe o dataframe, com data de início e fim, e um apelido. Retorna o dataframe com a coluna de topico\n",
    "def topic_classification(df, range_start, range_end, alias):\n",
    "    df_ = df.loc[(df['Data'] >= range_start) & (df['Data'] <= range_end)]\n",
    "    vocab_, count_vect_ = vocab_generation(df_['Conteúdo'].values.astype('U'))\n",
    "    best_param_ = best_param(vocab_)\n",
    "    lda_ = lda_model(vocab_,best_param_['n_components'],best_param_['learning_decay'])\n",
    "    topic_values_ = lda_.transform(vocab_)\n",
    "    \n",
    "    dict_={}\n",
    "    for i,topic in enumerate(lda_.components_):\n",
    "        dict_[i]=[count_vect_.get_feature_names()[i] for i in topic.argsort()[-3:]]\n",
    "    \n",
    "    df_['Topic'] = topic_values_.argmax(axis=1)\n",
    "    df_['Topic'] = df_['Topic'].astype(int)\n",
    "    df_['Topic']= df_['Topic'].apply(lambda x: dict_.get(x,x))\n",
    "    df_['Topic']= df_['Topic'].astype(str) + ' - ' + alias\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_week1 = topic_classification(df, '2020-01-01', '2020-01-07', 'week-1')\n",
    "df_week2 = topic_classification(df, '2020-01-08', '2020-01-14', 'week-2')\n",
    "df_week3 = topic_classification(df, '2020-01-15', '2020-01-21', 'week-3')\n",
    "df_week4 = topic_classification(df, '2020-01-22', '2020-01-31', 'week-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_week1, df_week2, df_week4, df_week4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>Veículo</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51284</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...</td>\n",
       "      <td>Correio Popular</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51271</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>JBS: acordo de acionistas entre J&amp;F e BNDESPar perde validade</td>\n",
       "      <td>O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...</td>\n",
       "      <td>Correio Popular</td>\n",
       "      <td>['bancos', 'consignado', 'banco'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51276</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>JBS: acordo de acionistas entre J&amp;F e BNDESPar perde validade</td>\n",
       "      <td>O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...</td>\n",
       "      <td>Revista Istoé</td>\n",
       "      <td>['bancos', 'consignado', 'banco'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51277</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...</td>\n",
       "      <td>UOL</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51267</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na Bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>Oferta de ações na Bolsa pode atingir R$ 200 bilhões \\nA exemplo do que ocorreu em 2019, empresa...</td>\n",
       "      <td>Estadão</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Data  \\\n",
       "0  51284 2020-01-01   \n",
       "1  51271 2020-01-01   \n",
       "2  51276 2020-01-01   \n",
       "3  51277 2020-01-01   \n",
       "4  51267 2020-01-01   \n",
       "\n",
       "                                                                    Título  \\\n",
       "0  Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "1            JBS: acordo de acionistas entre J&F e BNDESPar perde validade   \n",
       "2            JBS: acordo de acionistas entre J&F e BNDESPar perde validade   \n",
       "3  Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "4  Oferta de ações na Bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "\n",
       "                                                                                              Conteúdo  \\\n",
       "0  As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...   \n",
       "1  O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...   \n",
       "2  O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...   \n",
       "3  As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...   \n",
       "4  Oferta de ações na Bolsa pode atingir R$ 200 bilhões \\nA exemplo do que ocorreu em 2019, empresa...   \n",
       "\n",
       "           Veículo                                       Topic  \n",
       "0  Correio Popular    ['alta', 'ibovespa', 'mercado'] - week-1  \n",
       "1  Correio Popular  ['bancos', 'consignado', 'banco'] - week-1  \n",
       "2    Revista Istoé  ['bancos', 'consignado', 'banco'] - week-1  \n",
       "3              UOL    ['alta', 'ibovespa', 'mercado'] - week-1  \n",
       "4          Estadão    ['alta', 'ibovespa', 'mercado'] - week-1  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resposta Questão 4\n",
    "\n",
    "Foi assumido que os assuntos duram apenas uma semana, para que os tópicos não ficassem enviesado. Assim, cada semana foi quebrada em um dataset e os tópicos foram analisados com uso do algoritmo não-supervisionado LDA.\n",
    "\n",
    "A coluna 'Topic' no dataset final contém as 3 palavras mais relevante de cada tópico encontrado, bem como um alias para identificar a forma que eles apareceram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5\n",
    "\n",
    "Classificação de Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo\n",
    "df = pd.read_csv(filepath_or_buffer='classificação_publicacoes.csv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40829800373</td>\n",
       "      <td>HOUSTON , Dec. 5, 2019 /PRNewswire/ --  PAS Global LLC , the leading solution provider of indust...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39361377031</td>\n",
       "      <td>Special to the Star Tribune\\n\\nEastern cottonwoods are shedding innumerable seeds that are blown...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39055227972</td>\n",
       "      <td>Future Market Insights has announced the addition of the \" \" report to their offering\\n\\nThis pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40167958715</td>\n",
       "      <td>In Colorado, Gevo announced the signing of a Joint Development Agreement (JDA) with Leaf Resourc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39471347875</td>\n",
       "      <td>At first glance, it seems like a normal butcher s shop. Sausages hang in the window alongside bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  \\\n",
       "0  40829800373   \n",
       "1  39361377031   \n",
       "2  39055227972   \n",
       "3  40167958715   \n",
       "4  39471347875   \n",
       "\n",
       "                                                                                              Conteúdo  \\\n",
       "0  HOUSTON , Dec. 5, 2019 /PRNewswire/ --  PAS Global LLC , the leading solution provider of indust...   \n",
       "1  Special to the Star Tribune\\n\\nEastern cottonwoods are shedding innumerable seeds that are blown...   \n",
       "2  Future Market Insights has announced the addition of the \" \" report to their offering\\n\\nThis pr...   \n",
       "3  In Colorado, Gevo announced the signing of a Joint Development Agreement (JDA) with Leaf Resourc...   \n",
       "4  At first glance, it seems like a normal butcher s shop. Sausages hang in the window alongside bu...   \n",
       "\n",
       "   Relevante  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['Conteúdo'].values, df['Relevante'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Substituting break line\n",
    "    document = re.sub(r'\\n+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=100,min_df=2, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "X = tfidfconverter.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [80, 90],\n",
       "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [8, 10, 12],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rfc_cv_score = cross_val_score(grid_search.best_estimator_, X, y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predict = grid_search.best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All AUC Scores ===\n",
      "[0.72635963 0.8025641  0.79431217 0.81072555 0.80473186 0.80042872\n",
      " 0.723449   0.74052922 0.81157556 0.83924051]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.7853916328782377\n"
     ]
    }
   ],
   "source": [
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "acc=[]\n",
    "pre=[]\n",
    "rec=[]\n",
    "f1=[]\n",
    "auc=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=0,max_depth=md,max_leaf_nodes=ml)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)  \n",
    "    targs = y_test\n",
    "    acc.append(metrics.accuracy_score(targs, preds))\n",
    "    pre.append(metrics.precision_score(targs, preds))\n",
    "    rec.append(metrics.recall_score(targs, preds))\n",
    "    f1.append(metrics.f1_score(targs, preds))\n",
    "    auc.append(metrics.roc_auc_score(targs, preds))\n",
    "\n",
    "\n",
    "print(\"accuracy: mean {}, std {}\".format(np.mean(acc), np.std(acc)))  \n",
    "print(\"precision: mean {}, std {}\".format(np.mean(pre), np.std(pre)))  \n",
    "print(\"recall: mean {}, std {}\".format(np.mean(rec), np.std(rec)))\n",
    "print(\"f1: mean {}, std {}\".format(np.mean(f1), np.std(f1)))  \n",
    "print(\"area under curve (auc): mean {}, std {}\".format(np.mean(auc), np.std(auc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
