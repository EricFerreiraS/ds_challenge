{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1\n",
    "\n",
    "Classes:\n",
    "    - Promotor\n",
    "    - Detrator\n",
    "    - Neutro\n",
    "Só 100 notícias são classificadas\n",
    "Os conteúdos são rankeados por alcance\n",
    "    - No grupo com os 50 maiores alcances, todos são classificados manualmente\n",
    "    - O restante, 50 são selecionados aleatoriamentes e classificados manualmente\n",
    "    - Alcance por grupo\n",
    "    \n",
    "Calcular margem de erro do índice\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_top = 1000000 * (15/50)\n",
    "alcance_detrator_top = 1000000 * (8/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_res = 3000000 * (17/50)\n",
    "alcance_detrator_res = 3000000 * (7/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcance_promotor_total = alcance_promotor_top + alcance_promotor_res\n",
    "alcance_detrator_total = alcance_detrator_top + alcance_detrator_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_promotor_top = alcance_promotor_total / (alcance_promotor_top + alcance_detrator_top)\n",
    "indice_promotor_res = alcance_promotor_total / (alcance_promotor_res+alcance_detrator_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.869565217391304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_promotor_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666665"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_promotor_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margem_erro(populacao, amostra, p=0.5, z = 1.96):\n",
    "    '''\n",
    "    p: percentual (como não tem definido, escolhe 50% que é a pior)\n",
    "    z: valor referente a tabela de distribuição da normal (referente a 95% de confiança)\n",
    "    '''\n",
    "    return cmath.sqrt(-(z**2*p*(1-p)*(amostra-populacao))/(amostra*populacao)).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro TOP 50\n",
    "margem_erro(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13214317304279544"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro Restante\n",
    "margem_erro(550,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08946135105917713"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#margem de erro de amostra 100 da população de 600\n",
    "margem_erro(600,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resposta Questão 1\n",
    "\n",
    "A geração do índice depende do alcance de cada grupo. Para verificar a margem de erro do índice, a margem de erro dos grupos deve ser levado em consideração.\n",
    "\n",
    "Utilizando a fórmula para descobrir o tamanho da amostra (https://pt.wikihow.com/Calcular-o-Tamanho-de-uma-Amostra) os dados de cada amostra foram utilizadas. (obs: 95% de confiança foi utilizado)\n",
    "\n",
    "Para o grupo Top 50, como é um grupo controlado onde a população e amostra podem ser consideradas iguais, a margem de erro é 0. Já o restante, a marge de erro é cerca de 13% pois utilizo uma amostra de 50 de uma população de 550. Novamente, como o índice utiliza de ambos o grupo para compor o valor, essa margem será passada para o índice.\n",
    "\n",
    "Se ao invés de segmentar utilizasse uma amostra de 100, a margem de erro seria menor (cerca de 8.95%) o que seria melhor para o índice.\n",
    "\n",
    "Link de calculadoras:\n",
    "- https://www.solvis.com.br/calculos-de-amostragem/\n",
    "- https://pt.surveymonkey.com/mp/margin-of-error-calculator/\n",
    "- https://www.opinionbox.com/calculadora-margem-de-erro/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4\n",
    "\n",
    "Agrupar notícias por assunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo\n",
    "df = pd.read_csv(filepath_or_buffer='agrupamento_eventos_new.csv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>Veículo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51938</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Com inflação no foco, juro futuro termina em leve queda na B3</td>\n",
       "      <td>Com inflação no foco, juro futuro termina em leve queda na B3 \\nVictor Rezende e Lucas Hirata \\n...</td>\n",
       "      <td>Valor Econômico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52129</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>Reunión de la Fed impulsa a las bolsas internacionales en medio de preocupaciones por el coronav...</td>\n",
       "      <td>En medio de un entorno global en que los inversionistas siguen preocupados por la evolución del ...</td>\n",
       "      <td>Diario Financiero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51412</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>Líderes: Como as novas gerações se comportam no trabalho? Diretores de LinkedIn e Mercado Livre ...</td>\n",
       "      <td>O perfil de um funcionário mudou muito nos últimos anos. Os jovens que ingressam no mercado de t...</td>\n",
       "      <td>Yahoo Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51430</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>BTG recebe autorização do BC para abrir escritório em Lisboa</td>\n",
       "      <td>O BTG Pactual recebeu autorização do Banco Central (BC) para abrir um escritório de representaçã...</td>\n",
       "      <td>Valor Econômico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51334</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Ibovespa recua e vai abaixo de 117 mil pontos com aumento de tensão geopolítica; Natura sobe</td>\n",
       "      <td>SÃO PAULO (Reuters) - A bolsa paulista começava a semana com o Ibovespa em queda, contaminada pe...</td>\n",
       "      <td>Reuters Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        Data  \\\n",
       "0  51938  2020-01-22   \n",
       "1  52129  2020-01-29   \n",
       "2  51412  2020-01-08   \n",
       "3  51430  2020-01-08   \n",
       "4  51334  2020-01-06   \n",
       "\n",
       "                                                                                                Título  \\\n",
       "0                                        Com inflação no foco, juro futuro termina em leve queda na B3   \n",
       "1  Reunión de la Fed impulsa a las bolsas internacionales en medio de preocupaciones por el coronav...   \n",
       "2  Líderes: Como as novas gerações se comportam no trabalho? Diretores de LinkedIn e Mercado Livre ...   \n",
       "3                                         BTG recebe autorização do BC para abrir escritório em Lisboa   \n",
       "4         Ibovespa recua e vai abaixo de 117 mil pontos com aumento de tensão geopolítica; Natura sobe   \n",
       "\n",
       "                                                                                              Conteúdo  \\\n",
       "0  Com inflação no foco, juro futuro termina em leve queda na B3 \\nVictor Rezende e Lucas Hirata \\n...   \n",
       "1  En medio de un entorno global en que los inversionistas siguen preocupados por la evolución del ...   \n",
       "2  O perfil de um funcionário mudou muito nos últimos anos. Os jovens que ingressam no mercado de t...   \n",
       "3  O BTG Pactual recebeu autorização do Banco Central (BC) para abrir um escritório de representaçã...   \n",
       "4  SÃO PAULO (Reuters) - A bolsa paulista começava a semana com o Ibovespa em queda, contaminada pe...   \n",
       "\n",
       "             Veículo  \n",
       "0    Valor Econômico  \n",
       "1  Diario Financiero  \n",
       "2       Yahoo Brasil  \n",
       "3    Valor Econômico  \n",
       "4     Reuters Brasil  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-01-22', '2020-01-29', '2020-01-08', '2020-01-06',\n",
       "       '2020-01-28', '2020-01-02', '2020-01-23', '2020-01-07',\n",
       "       '2020-01-20', '2020-01-15', '2020-01-01', '2020-01-14',\n",
       "       '2020-01-17', '2020-01-27', '2020-01-13', '2020-01-16',\n",
       "       '2020-01-09', '2020-01-21', '2020-01-10', '2020-01-03',\n",
       "       '2020-01-18', '2020-01-26', '2020-01-19', '2020-01-12',\n",
       "       '2020-01-05', '2020-01-24', '2020-01-11', '2020-01-04',\n",
       "       '2020-01-25'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando as datas únicas\n",
    "df.Data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordenando pela data\n",
    "df = df.sort_values(by=['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando data em datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import de bibliotecas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import corpus\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#stopwords em portugues + duas palavras que não estavam incluídas\n",
    "stopwords_pt = corpus.stopwords.words('portuguese')\n",
    "stopwords_pt.append('ainda')\n",
    "stopwords_pt.append('ser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geração do vocabulário, onde seleciono apenas palavras que aparecem em menos de 80% no documento e\n",
    "#em pelo menos 2 documentos diferentes. Também são retirados as stopwords e consideram apenas palavras com mais \n",
    "#de 3 letras. Todas as palavras são colocadas em caixa baixa\n",
    "def vocab_generation(df):\n",
    "    count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=stopwords_pt, lowercase=True, token_pattern=r'(?u)\\b[a-zA-Z_.]{3,}\\b')\n",
    "    doc_term_matrix = count_vect.fit_transform(df)\n",
    "    return doc_term_matrix, count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#busca pelos melhores parâmetros para o algoritmo. Quantidade de topicos e taxa de aprendizado\n",
    "def best_param(df,n_topic=[3,4,5,6,7,8,9],learning_decay=[.5, .7, .9]):\n",
    "    search_params = {'n_components': n_topic, 'learning_decay': learning_decay}\n",
    "    lda = LatentDirichletAllocation()\n",
    "    model = GridSearchCV(lda, param_grid=search_params,n_jobs=2,cv=5)\n",
    "    model.fit(df)\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo LDA\n",
    "def lda_model(df,n_components_, learning_decay_):\n",
    "    LDA = LatentDirichletAllocation(n_components=n_components_,learning_decay =learning_decay_, random_state=7)\n",
    "    LDA.fit(df)\n",
    "    return LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que recebe o dataframe, com data de início e fim, e um apelido. Retorna o dataframe com a coluna de topico\n",
    "def topic_classification(df, range_start, range_end, alias):\n",
    "    df_ = df.loc[(df['Data'] >= range_start) & (df['Data'] <= range_end)]\n",
    "    vocab_, count_vect_ = vocab_generation(df_['Conteúdo'].values.astype('U'))\n",
    "    best_param_ = best_param(vocab_)\n",
    "    lda_ = lda_model(vocab_,best_param_['n_components'],best_param_['learning_decay'])\n",
    "    topic_values_ = lda_.transform(vocab_)\n",
    "    \n",
    "    dict_={}\n",
    "    for i,topic in enumerate(lda_.components_):\n",
    "        dict_[i]=[count_vect_.get_feature_names()[i] for i in topic.argsort()[-3:]]\n",
    "    \n",
    "    df_['Topic'] = topic_values_.argmax(axis=1)\n",
    "    df_['Topic'] = df_['Topic'].astype(int)\n",
    "    df_['Topic']= df_['Topic'].apply(lambda x: dict_.get(x,x))\n",
    "    df_['Topic']= df_['Topic'].astype(str) + ' - ' + alias\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df_week1 = topic_classification(df, '2020-01-01', '2020-01-07', 'week-1')\n",
    "df_week2 = topic_classification(df, '2020-01-08', '2020-01-14', 'week-2')\n",
    "df_week3 = topic_classification(df, '2020-01-15', '2020-01-21', 'week-3')\n",
    "df_week4 = topic_classification(df, '2020-01-22', '2020-01-31', 'week-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_week1, df_week2, df_week4, df_week4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Data</th>\n",
       "      <th>Título</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>Veículo</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51284</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...</td>\n",
       "      <td>Correio Popular</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51271</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>JBS: acordo de acionistas entre J&amp;F e BNDESPar perde validade</td>\n",
       "      <td>O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...</td>\n",
       "      <td>Correio Popular</td>\n",
       "      <td>['bancos', 'consignado', 'banco'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51276</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>JBS: acordo de acionistas entre J&amp;F e BNDESPar perde validade</td>\n",
       "      <td>O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...</td>\n",
       "      <td>Revista Istoé</td>\n",
       "      <td>['bancos', 'consignado', 'banco'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51277</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...</td>\n",
       "      <td>UOL</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51267</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Oferta de ações na Bolsa brasileira pode atingir até R$ 200 bi este ano</td>\n",
       "      <td>Oferta de ações na Bolsa pode atingir R$ 200 bilhões \\nA exemplo do que ocorreu em 2019, empresa...</td>\n",
       "      <td>Estadão</td>\n",
       "      <td>['alta', 'ibovespa', 'mercado'] - week-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Data  \\\n",
       "0  51284 2020-01-01   \n",
       "1  51271 2020-01-01   \n",
       "2  51276 2020-01-01   \n",
       "3  51277 2020-01-01   \n",
       "4  51267 2020-01-01   \n",
       "\n",
       "                                                                    Título  \\\n",
       "0  Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "1            JBS: acordo de acionistas entre J&F e BNDESPar perde validade   \n",
       "2            JBS: acordo de acionistas entre J&F e BNDESPar perde validade   \n",
       "3  Oferta de ações na bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "4  Oferta de ações na Bolsa brasileira pode atingir até R$ 200 bi este ano   \n",
       "\n",
       "                                                                                              Conteúdo  \\\n",
       "0  As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...   \n",
       "1  O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...   \n",
       "2  O acordo de acionistas da JBS com o Banco Nacional de Desenvolvimento Econômico e Social (BNDES)...   \n",
       "3  As empresas brasileiras devem continuar se financiando na Bolsa para promover sua expansão em 20...   \n",
       "4  Oferta de ações na Bolsa pode atingir R$ 200 bilhões \\nA exemplo do que ocorreu em 2019, empresa...   \n",
       "\n",
       "           Veículo                                       Topic  \n",
       "0  Correio Popular    ['alta', 'ibovespa', 'mercado'] - week-1  \n",
       "1  Correio Popular  ['bancos', 'consignado', 'banco'] - week-1  \n",
       "2    Revista Istoé  ['bancos', 'consignado', 'banco'] - week-1  \n",
       "3              UOL    ['alta', 'ibovespa', 'mercado'] - week-1  \n",
       "4          Estadão    ['alta', 'ibovespa', 'mercado'] - week-1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('agrupamento_eventos_resposta.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resposta Questão 4\n",
    "\n",
    "Foi assumido que os assuntos duram apenas uma semana, para que os tópicos não ficassem enviesado. Assim, cada semana foi quebrada em um dataset e os tópicos foram analisados com uso do algoritmo não-supervisionado LDA.\n",
    "\n",
    "A coluna 'Topic' no dataset final contém as 3 palavras mais relevante de cada tópico encontrado, bem como um alias para identificar a forma que eles apareceram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5\n",
    "\n",
    "Classificação de Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo\n",
    "df = pd.read_csv(filepath_or_buffer='classificação_publicacoes.csv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40829800373</td>\n",
       "      <td>HOUSTON , Dec. 5, 2019 /PRNewswire/ --  PAS Global LLC , the leading solution provider of indust...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39361377031</td>\n",
       "      <td>Special to the Star Tribune\\n\\nEastern cottonwoods are shedding innumerable seeds that are blown...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39055227972</td>\n",
       "      <td>Future Market Insights has announced the addition of the \" \" report to their offering\\n\\nThis pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40167958715</td>\n",
       "      <td>In Colorado, Gevo announced the signing of a Joint Development Agreement (JDA) with Leaf Resourc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39471347875</td>\n",
       "      <td>At first glance, it seems like a normal butcher s shop. Sausages hang in the window alongside bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  \\\n",
       "0  40829800373   \n",
       "1  39361377031   \n",
       "2  39055227972   \n",
       "3  40167958715   \n",
       "4  39471347875   \n",
       "\n",
       "                                                                                              Conteúdo  \\\n",
       "0  HOUSTON , Dec. 5, 2019 /PRNewswire/ --  PAS Global LLC , the leading solution provider of indust...   \n",
       "1  Special to the Star Tribune\\n\\nEastern cottonwoods are shedding innumerable seeds that are blown...   \n",
       "2  Future Market Insights has announced the addition of the \" \" report to their offering\\n\\nThis pr...   \n",
       "3  In Colorado, Gevo announced the signing of a Joint Development Agreement (JDA) with Leaf Resourc...   \n",
       "4  At first glance, it seems like a normal butcher s shop. Sausages hang in the window alongside bu...   \n",
       "\n",
       "   Relevante  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Conteúdo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3139</td>\n",
       "      <td>3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Conteúdo\n",
       "Relevante                \n",
       "0          3139      3139\n",
       "1           126       126"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base desbalanceada\n",
    "df.groupby('Relevante').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando os datasets\n",
    "df_0 = df[df['Relevante']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['Relevante']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um sample com quantidade igual\n",
    "frames = [df_0.sample(126, random_state=0),df_1]\n",
    "df_final = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#misturando o dataset\n",
    "df_final = sklearn.utils.shuffle(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Conteúdo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Conteúdo\n",
       "Relevante               \n",
       "0          126       126\n",
       "1          126       126"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.groupby('Relevante').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_final['Conteúdo'].values, df_final['Relevante'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpeza de dados\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Substituting break line\n",
    "    document = re.sub(r'\\n+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando vetor com TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=100,min_df=2, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "X = tfidfconverter.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realizando grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "bootstrap = [False]\n",
    "max_depth = [30, 40, 50]\n",
    "max_features = ['sqrt']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [800]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [30, 40, 50],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [800]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: mean 0.6949803921568628, std 0.06807300963320836\n",
      "precision: mean 0.6786153846153846, std 0.060302418332971786\n",
      "recall: mean 0.7603312629399586, std 0.058972981090160755\n",
      "f1: mean 0.7147081678237759, std 0.04542881623410436\n",
      "area under curve (auc): mean 0.6951089895167856, std 0.07207667308240753\n"
     ]
    }
   ],
   "source": [
    "#com cross-validation = 5, treinando o classificador\n",
    "kf = KFold(n_splits=5)\n",
    "acc=[]\n",
    "pre=[]\n",
    "rec=[]\n",
    "f1=[]\n",
    "auc=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #clf = DecisionTreeClassifier(random_state=0,max_depth=md,max_leaf_nodes=ml)\n",
    "    clf = RandomForestClassifier(bootstrap=False, max_depth=grid_search.best_params_['max_depth'],\n",
    "                                 max_features=grid_search.best_params_['max_features']\n",
    "                                 ,min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                                 min_samples_split=grid_search.best_params_['min_samples_split'],n_estimators=800)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)  \n",
    "    targs = y_test\n",
    "    acc.append(metrics.accuracy_score(targs, preds))\n",
    "    pre.append(metrics.precision_score(targs, preds))\n",
    "    rec.append(metrics.recall_score(targs, preds))\n",
    "    f1.append(metrics.f1_score(targs, preds))\n",
    "    auc.append(metrics.roc_auc_score(targs, preds))\n",
    "\n",
    "\n",
    "print(\"accuracy: mean {}, std {}\".format(np.mean(acc), np.std(acc)))  \n",
    "print(\"precision: mean {}, std {}\".format(np.mean(pre), np.std(pre)))  \n",
    "print(\"recall: mean {}, std {}\".format(np.mean(rec), np.std(rec)))\n",
    "print(\"f1: mean {}, std {}\".format(np.mean(f1), np.std(f1)))  \n",
    "print(\"area under curve (auc): mean {}, std {}\".format(np.mean(auc), np.std(auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open('model_question5','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resposta Pergunta 5\n",
    "\n",
    "Com um dataset desbalanceado, foi necessário realizar um undersample da classe que tinha mais valor para que não trouxesse muito vies pro classificador. Foi utilizado o classificador Random Forest por ser um ensamble, otimizando a classificação. Os resultados foram interessente se levar em consideração a pouca quantidade de dados. Para melhorar o classificador, mais dados devem ser utilizados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
